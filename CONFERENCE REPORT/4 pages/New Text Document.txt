\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{\LARGE{Autonomous Garbage Collector Rover Using Image Processing}\\
{\footnotesize \textsuperscript{}Autonomously and Manually Controlled Garbage Collector Rover Using Image Processing}
}

\maketitle

\begin{abstract}
We are presenting a smart robot that could present a viable solution towards efficient waste management which is based on embedded, digital image processing. The system is designed so that it can automatically detect and collect the garbage. This report describes the basic idea of detection and collection. The detection is done by using the image processing model SSD Mobilenet v2. The real time video taken by the USB camera will be processed by the Raspberry Pi.  For each frame taken, Raspberry Pi will detect any garbage present in the frame and send signals to the robot. Our robot will calculate its position, calibrate the motors according to the position of the garbage so that it will go to the acquired position and collect the garbage. The collected garbage will be categorized as Paper, Plastic, Metal and Glass and kept it in different sections of a basket attached to the back of the robot.
\end{abstract}

\begin{IEEEkeywords}
autonomous,garbage,robot,detection,collection
\end{IEEEkeywords}

\section{Introduction}
One of the most adverse impacts of poor waste management, is the incidence and prevalence of diseases such as malaria and respiratory problems, as well as other illnesses through the contamination of ground water, soil and air. The main objective of this project is to recognize and categorize the waste autonomously, which require minimal human intervention. The robot will collect waste categorizing them as Plastic, Paper, Glass and Metal and put them in a container creating a cleaner and safer environment for humans to live. 


\section{Literature Review}

There are numerous methods that are used to make a garbage collecting robot. These methods provide the information about various techniques used for a garbage collecting robot. Some of these methods do have limitations which are proposed in this section.

A cost effective garbage cleaning robot is developed and that is named as “Thooyan”\cite{b1}. The system (road cleaning robot) consists of very simple but highly efficient mechanism. The main components consist of a rotating brush assembly (rake), a unique tilting wedge, a conveyor system and a garbage collection unit. Robot is programmed in a certain pattern so as to navigate automatically and detect obstacles to move in a free path. If encountered by a moving obstacle, the robot is programmed to pause for duration of 50 seconds and then sense again to move or it will take turn of 180 degree. A solar panel is provided for partial charging of the battery. Since this robot uses conveyor belt the cost of the whole system will be more which adds limitation to this method. But it gave an idea or advantage to use solar panels which in turn helps to reduce the power consumption. This robot is the small step to change the manual waste collection and ensures the safety of sanitary workers. The limitation of this robot is that it can only run on free paths, where else our robot can run in any unknown location.

The robot, called ROAR\cite{b2} is transported to the refuse collection site on the back of a refuse truck. An operator presses a button on the truck and this prompts a drone to be launched from its roof and begin scanning the surrounding area to locate bins. The locations of the bins are then relayed to the ground-based robot. ROAR navigates its way to each bin using a map of the area and the likely locations of bins, as well as the data provided by the drone. GPS and LiDAR are used to help it navigate and avoid obstacles. Inertial measurement unit (IMU) data, from accelerometer and gyroscope sensors, are used to help the robot keep track of its position. Once ROAR has arrived at the bin, it uses cameras and LiDAR to position itself, before extending its arms and lifting the bin onto its built-in platform. It then returns to the refuse truck and lifts the bin into position to be emptied.



In all, our robot is different from others because it has a high power motors which allows it to move over almost any medium sized stones or rocks.It works in both autonomous and human control modes. It has a custom built obstacle avoidance program which allows it to move in any unknown location. It has a GPS so that if there is any attempt of theft immediate actions can be taken. It has a custom built robot arm that can carry garbage up to 1kg and place it in different sections of the basket attached behind it. As a result, there is no need of any categorization by a human after the garbage has been collected. The robot will collect waste categorizing them as Plastic, Paper, Glass and Metal and put them in a container creating a cleaner and safer environment for humans to live. 



\section{Methodology}
Our project is basically the idea of detection and collection. The detection part will be done by the Raspberry Pi and the collection of garbage will be done by the robot. As a result, we have divided our project into two major parts.

\subsection{Detection}\label{AA}
The system will be trained through a dataset by using machine learning technique such as SINGLE SHOT DETECTION (SSD). We developed our dataset which consists a total of 2518 RGB images for both training and testing images with JPG format. We hand collected the dataset as well as used an existing dataset from Kaggle \cite{b3}. We have taken images from different angles and lights so that our machine can learn variation and angles of the garbage. We re-sized those images into 512*384 pixels for training model to run without any error and delay. Our images has been labelled by labelImg application for supervised learning into four classes (paper, plastic, glass and metal). After la-belling, our data is ready to train and test. We used 80 percent of the dataset to train and 20 percent to test. Finally we implemented the developed dataset in a Raspberry Pi which helps our robot to collect waste and automatically categorizing them as Plastic, Paper, Glass and Metal. As the system works independently, there is no need of human mediation to control it. As we are using a USB camera, our robot can detect a garbage with in 1 feet of the robot. But if we switch to a better camera, the range of detection will significantly increase.
\subsection{Collection}
For the collection part, the robot will at first go in front of the garbage and with the help of sonar sensors will calculate the exact distance between the garbage and the robot. Later it will send the data to the Arduino which will decide if it is possible to collect the garbage or not within that calculated distance. If it is possible, Arduino will send a signal to the robotic arm to grab the waste in front of it. Once the garbage is collected, it will drop the garbage in a basket which will be divided into 4 parts (Paper/Plastic/Metal/Glass). The basket will be rotating based on which type of garbage has been collected. So, if paper is collected the basket will rotate to the side of the paper and the robotic arm will drop the paper in the specific paper part of the basket.

\subsection{Procedure}
At first our robot will detect a garbage with the help of trained model in Raspberry pi. After processing the data, it will send signals to the robot to go to the specific location of the garbage and finally collect it in a specific part of the basket or container.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.4]{fig.png}}
	\caption{Process of Autonomous Garbage Collection}
	\label{fig}
\end{figure}


\subsection{Usecase/Subsystem}

There are basically two use case for this project. One of them is autonomous and the other is human control.\\


\centerline{\textbf {USECASE-1 (AUTONOMOUS)}}

Here the Garbage Collector Robot will be a driverless autonomous vehicle specifically designed to collect waste which require no human intervention. It will automatically detect the waste, move towards it and grab the waste with its robotic arm. Once the waste is collected, it will automatically drop the waste in its specified part(Paper/Plastic/Metal/Glass) of the container.\\

\centerline{\textbf {USECASE-2 (HUMAN CONTROL)}}

Here the Garbage Collector Robot can be controlled manually by a human with the help of an app. The robot can be manually sent front, back, right and left using button controls on the app and can also pickup any waste from the ground using the robotic arm.\\


\section{SYSTEM DESIGN / ARCHITECTURE}\label{SCM}

The robot is basically of 4 main parts. At first for the software i.e. the detection part, we used Raspberry Pi which was trained to detect wastes like Paper, Plastic, Metal and Glass. Next, for the movement of the robot we used 4WD robot vehicle that allows the robot to move in any direction it wants to. Thirdly, we attached a Robot Arm to the vehicle which gradually grabs the garbage it detects. Finally, the robot has a rotating bin/basket behind it which collects the garbage grabbed by the robotic arm. So, if paper is collected the basket will rotate to the side of the paper portion of the container and the robot arm will drop the paper in the specific paper part of the basket. As a result, Paper, Plastic, Metal and Glass will be collected separately in different portions of the basket.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.1]{ARCHITECTURE.jpg}}
	\caption{Architecture of Autonomous Garbage Collection Rover}
	\label{fig}
\end{figure}




\section{SINGLE SHOT MULTIBOX DETECTOR(SSD)— REAL-TIME OBJECT DETECTION IN DEEP LEARNING}

In the field of computer vision, convolution neural networks excel at image classification, which consists of categorising images, given a set of classes and having the network determine the strongest class present in the image. 


	
 \textbf{Single Shot: } This means that the tasks of object localization and classification are done in a single forward pass of the network. SSD’s architecture builds on the venerable VGG-16\cite{b6} architecture, but discards the fully connected layers. 
 
	\begin{figure}[htbp]
		\centerline{\includegraphics[scale=0.4]{ssd.png}}
		\caption{VGG Architecture}
		\label{fig}
	\end{figure}

	
\textbf{Multibox: } MultiBox starts with the priors as predictions and attempt to regress closer to the ground truth bounding boxes. More default boxes results in more accurate detection, although there is an impact on speed. Having MultiBox on multiple layers results in better detection as well, due to the detector running on features at multiple resolutions. 

	


\section{ROBOT VEHICLE}
The robot vehicle is considered to be the main part of the robot. It has customized metal body of Length: 30 cm, Width: 26 cm, Height: 13 cm and Wheel Diameter: 11cm. It is 2 cm above the ground level. All the important devices like Raspberry Pi, Arduino Mega, etc. has been kept inside this vehicle's body. The body contains an extended part in the front to attach the robot arm which will collect the garbage. It has a torque power of 10kg per square cm.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.5]{heightlengthwidth.png}}
	\caption{Height, Wheel Diameter, Length and Width of the Robot Vehicle}
	\label{fig}
\end{figure}


\subsection{Motor}

\textbf {Toyota Denso Window Motor:}
This motor has been used to rotate the wheel of the robot veehicle. It is powerful enough to overcome small or medium sized obstacles. It has a RPM :  80±10rpm (no load) and 55±15rpm (with load)
\\Max Voltage: 12v
\\No Load Current: $\le$ 2A
\\Stall Current: $\le$ 8A  
\\Rated Torque: 3 N.m $\sim$ 30.6 kg-cm 
\\Stall Torque: 9.8N.m $\sim$ 100kg-cm.


\subsection{Calculations}

Using the right hand rule equation:$\overrightarrow{\rm \tau}=\overrightarrow{\rm \ell}\times\overrightarrow{\rm \digamma}=\digamma\ell\sin\theta\hat{\eta}$

Here, $\rm \tau$ =Torque, moment or moment of force, $\rm \ell$ = Length and $\rm \digamma$= Force\\\\
When robot is moving forward:
Direction of F is to the left creating 0-degree angle with the width for Right-sided motors.
Direction of F is to the left creating 180-degree angle with the width for Left-sided motors.\\
So, in both cases, length of width is cancelled out as sin(0)=0.
But, Direction of F is to the left creating 90-degree angle with the length for Right-sided motors.
Direction of F is to the left creating 90-degree angle with the width for Left-sided motors.
So, for both cases, torque value should me maximum as sin(90)=1. One Denso motor gives torque of 100 kg-cm. Length of the robot: 30cm\\

So, Maximum weight 1 motor can lift: 100/30 kg =3.3 kg
\\Maximum weight 4 motor can lift: 3.3kg x 4 = 13.33 kg
\\Same mechanism for moving backward, right and left.\\

\textbf{Note:} We have tested with 15kg weight above the robot and it worked absolutely fine. So, we can say the motors are much more powerful than it was scripted by the company.


\subsection{Power Consumption}

One motor consumes approximately 2$\sim$2.5A depending on its movement. For instance, while moving forward and backward it consumes 2A. On the other hand, while moving right and left it consumes 2.5A. It is because of the drifting of both motor at the opposite directions. While moving right, left sided motors rotate clockwise and right sided motors rotate counter clockwise. To cancel out this opposite direction drifting each motors consumes higher current than moving forward or backward.
 
So, In total 4 motors consumes: (2$\sim$2.5 x 4)A = 8 $\sim$ 10 A.
\\We are using 12v 7.5Ah battery. 
\\So, the uptime of our robot is: 7.5/10 hr = 0.75 hr = 45 mins.
\\It means, Our robot can be driven up to 45mins straight with full load and working capacity. 

As our battery takes 2A initial current for charging it will take (7.5/2) hr = 3.75 hr = 3hr 45 mins to fully charged. 	


\section{ROBOT ARM}

We have run some experiments regarding the grabbing part of the robot arm. The most available servo motor in Bangladesh is MG996R / MG995. Using this servo, it is quite difficult to grab the object from the ground using 6DOF arm. Though we bought 6 DOF arm but we modified the structure of the arm so that it can grab the objects so frequently. So, our custom built robot arm can pick up garbage of a weight limit of 1kg.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.4]{arm.png}}
	\caption{Modified Robot Arm and Robot Arm with required Length}
	\label{fig}
\end{figure}


\subsection{Calculations}

Torque of MG996R: 9.4 kg-cm (at 4.8 v), Torque of MG996R: 11 kg-cm (at 6 v), Operating Voltage: 4.8 v ~ 6.6 v
\\We are operating at 6 v using 6v 4.5Ah battery. So, we are getting the maximum torque of 11kg-cm.


\subsection{Torque Equation}

Using the right hand rule equation:$\overrightarrow{\rm \tau}=\overrightarrow{\rm \ell}\times\overrightarrow{\rm \digamma}=\digamma\ell\sin\theta\hat{\eta}$

Here, $\rm \tau$ =Torque, moment or moment of force, $\rm \ell$ = Length and $\rm \digamma$= Force\\
The length from Shoulder (Servo2) to the gripper top is: $\sim$40 cm. Maximum weight that 1 MG996R servo can lift: 11 kg-cm / 40 cm = 275 gm
\\So, total weight shoulder servos can lift:275 $\times$ 2 gm = 550 gm. Equipment’s total weight above Servo2 : \\Weight of Claw + Weight of U Bracket $\times$ 3  + MG996R servo $\times$ 4 + Multifunctional Bracket $\times$ 3 + L-type Bracket $\times$1

= (56 + 22 $\times$ 3 + 55 $\times$ 4 + 16 $\times$ 3 + 6) gm 

= 396 gm, which is greater than 275 gm but less than 550gm

So, Shoulder servos can lift total weight of garbage = (550 – 396) gm = 104 gm which is enough for our project. 

\subsection{Modifications Necessary}

If we used 1 servo in the shoulder of the 6 DOF then the height from shoulder to the gripper top would be still approximately 40 cm. 
Then it can lift maximum weight of = 11 kg-cm / 40 cm =0.275 kg  $\sim$275 gm.\\
But component’s total weight above Shoulder would be 
= (56 + 22 $\times$ 3 + 55 $\times$ 4 + 16 $\times$ 3 + 6) gm 
= 396 gm which is greater than 275 gm.
So, it will not work properly.\\ 

\textbf{Note:} We ran some tests earlier on 6DOF and we saw that Shoulder servo falls down with the excessive weight as it’s torque is not compatible with that much weight. 
So, we modified and used two servos together in the shoulder with the help of a customized metallic plate. After modification, our robot arm can grab the garbage and lift it properly. As our robotic hand is compatible with XYZ (3D) rotation so it is enough for our project. 


\subsection{Power Consumption}

We have used 7 servos for robotic hand, 1 servo to rotate the basket, 1 for rotating camera. So in total 9 servos are used. 
Each servo has a stall current of 1.4 A. 
So total Stall current: (9 $\times$ 1.4) A = 12.6 A
We are using 6v 4.5Ah to power up the robot arm servos along with basket servo and camera servo.
So the uptime of robotic hand and basket and camera rotation function is: (4.5/12.6) hr = 0.38 hour $\sim$ 22 mins.
This is the uptime with full load functionalities. All the servos will not work at full load capacity because of their position. Neither all the servos are at the maximum distance from the gripper of the robotic hand nor they lift the maximum weight while picking garbage. So power(current) consumption is not equal for all the servos. We noticed that the actual uptime is almost triple of this time which is more than enough for our project. 
The idle current draw for each servo: 10mA which is so low and we can ignore it.  




\section*{CONCLUSION}

This system isolates waste automatically utilizing sensors, motors and detection software.The proposed system concentrates on identification, classification and segregation of waste. As the system works independently, there is no need of human mediation to control or to do any assignment. Utilizing Raspberry Pi and USB camera, the characterization result of images taken will automatically categorize the garbage as Plastic, Paper, Glass and Metal and send signals to the robot to collect the garbage. Once our modified robot gets the signal it will move towards the garbage and collect it using the modified robot arm. Finally the garbage will be dumped in separate portions of a basket based on the type of garbage collected. Our robot is different from other garbage collector robots as it can run in any unknown location. Sonar sensors allow it to avoid obstacles. Moreover, we used SSD Mobile Lite for detection of garbage which has lower processing power but great detection level. As a result, it will not heat up the processor of Raspberry Pi allowing it to run smoothly.



\begin{thebibliography}{00}
\bibitem{b1} Nurlansa, Osiany, Dewi Anisa Istiqomah, and Mahendra Astu Sanggha Pawitra. "AGATOR (automatic garbage collector) as automatic garbage collector robot model." International Journal of Future Computer and Communication 3.5 (2014): 367.

\bibitem{b2}Wattanasophon, S., and Sarinee Ouitrakul. "Garbage collection robot on the beach using wireless communications." Int. Proc. Chem. Biol. Environ. Eng 66 (2014): 92-96.

\bibitem{b3} Available: https://www.kaggle.com/asdasdasasdas/garbage-classification



\end{thebibliography}
\vspace{12pt}


\end{document}
